"""
ç®€æ´çš„UIç•Œé¢ - ä½¿ç”¨Streamlit
"""
import streamlit as st
from code_assistant import CodeAssistant
from langchain_core.messages import HumanMessage, AIMessage
import os
from dotenv import load_dotenv

load_dotenv()


def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "selected_model" not in st.session_state:
        st.session_state.selected_model = "deepseek-ai/DeepSeek-V3.1-Terminus"
    if "continuous_mode" not in st.session_state:
        st.session_state.continuous_mode = False
    if "assistant" not in st.session_state:
        try:
            st.session_state.assistant = CodeAssistant(model_name=st.session_state.selected_model)
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            st.stop()
    if "continuous_agent" not in st.session_state:
        try:
            from code_assistant_continous import CodeQualityAgent
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                st.session_state.continuous_agent = CodeQualityAgent(api_key)
            else:
                st.session_state.continuous_agent = None
        except Exception as e:
            st.session_state.continuous_agent = None
            # è¿ç»­æ€è€ƒåˆå§‹åŒ–å¤±è´¥ï¼Œä½†ä¸å½±å“æ™®é€šæ¨¡å¼ä½¿ç”¨


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="ä»£ç åŠ©æ‰‹",
        page_icon=None,  # æ— å›¾æ ‡
        layout="centered",
        initial_sidebar_state="collapsed"  # é»˜è®¤æ”¶èµ·ä¾§è¾¹æ 
    )
    
    # éšè—Streamlité»˜è®¤çš„èœå•å’Œé¡µè„š
    hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
    """
    st.markdown(hide_streamlit_style, unsafe_allow_html=True)
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv("OPENAI_API_KEY"):
        st.error("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        st.info("åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œæ·»åŠ ï¼šOPENAI_API_KEY=your_key")
        st.stop()
    
    # åˆå§‹åŒ–
    init_session_state()
    
    # æ ‡é¢˜å’Œæ¨¡å‹é€‰æ‹©
    col_title, col_model, col_continuous = st.columns([2, 1, 1])
    with col_title:
        st.title("ä»£ç åŠ©æ‰‹")
        st.caption("åŸºäºLangGraphçš„æ™ºèƒ½ä»£ç ç”Ÿæˆã€ä¼˜åŒ–å’Œå®¡æŸ¥å·¥å…·")
    with col_model:
        # æ¨¡å‹é€‰æ‹©
        from code_assistant import AVAILABLE_MODELS
        model_display_names = list(AVAILABLE_MODELS.keys())
        current_model_display = None
        for display_name, model_id in AVAILABLE_MODELS.items():
            if model_id == st.session_state.selected_model:
                current_model_display = display_name
                break
        
        if current_model_display is None:
            current_model_display = model_display_names[0]
            st.session_state.selected_model = AVAILABLE_MODELS[current_model_display]
        
        selected_display = st.selectbox(
            "æ¨¡å‹",
            model_display_names,
            index=model_display_names.index(current_model_display),
            key="model_selector"
        )
        
        # å¦‚æœæ¨¡å‹æ”¹å˜ï¼Œé‡æ–°åˆå§‹åŒ–åŠ©æ‰‹
        new_model = AVAILABLE_MODELS[selected_display]
        if new_model != st.session_state.selected_model:
            st.session_state.selected_model = new_model
            try:
                st.session_state.assistant = CodeAssistant(model_name=new_model)
                # æ¸…é™¤å¯¹è¯å†å²ï¼ˆå› ä¸ºä¸åŒæ¨¡å‹çš„ä¸Šä¸‹æ–‡å¯èƒ½ä¸å…¼å®¹ï¼‰
                st.session_state.messages = []
                st.rerun()
            except Exception as e:
                st.error(f"åˆ‡æ¢æ¨¡å‹å¤±è´¥: {e}")
                st.stop()
    
    with col_continuous:
        st.write("")  # å ä½
        st.write("")  # å ä½
        # è¿ç»­æ€è€ƒå¼€å…³
        continuous_mode = st.toggle(
            "è¿ç»­æ€è€ƒ",
            value=st.session_state.continuous_mode,
            key="continuous_toggle",
            help="å¼€å¯åä½¿ç”¨è¿ç»­å¯¹è¯æ¨¡å¼ï¼ˆcode_assistant_continous.pyï¼‰ï¼Œæ”¯æŒè®°å¿†åŠŸèƒ½å’Œè¯¦ç»†æ—¥å¿—"
        )
        
        # å¦‚æœè¿ç»­æ€è€ƒçŠ¶æ€æ”¹å˜ï¼Œæ¸…é™¤å¯¹è¯å†å²å¹¶é‡æ–°åˆå§‹åŒ–
        if continuous_mode != st.session_state.continuous_mode:
            st.session_state.continuous_mode = continuous_mode
            st.session_state.messages = []
            # é‡æ–°åˆå§‹åŒ–è¿ç»­æ€è€ƒåŠ©æ‰‹
            if continuous_mode:
                try:
                    from code_assistant_continous import CodeQualityAgent
                    api_key = os.getenv("OPENAI_API_KEY")
                    if api_key:
                        st.session_state.continuous_agent = CodeQualityAgent(api_key)
                    else:
                        st.session_state.continuous_agent = None
                        st.warning("è¿ç»­æ€è€ƒéœ€è¦ API å¯†é’¥")
                except Exception as e:
                    st.session_state.continuous_agent = None
                    st.warning(f"è¿ç»­æ€è€ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            st.rerun()
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for message in st.session_state.messages:
        with st.chat_message("user" if isinstance(message, HumanMessage) else "assistant"):
            st.markdown(message.content)
    
    # åœ¨è¾“å…¥æ¡†ä¸Šæ–¹æ˜¾ç¤ºè¿ç»­æ€è€ƒçŠ¶æ€æç¤º
    if st.session_state.continuous_mode:
        st.info("ğŸ”„ è¿ç»­æ€è€ƒå·²å¼€å¯ - ä½¿ç”¨ code_assistant_continous.pyï¼Œæ”¯æŒè®°å¿†åŠŸèƒ½")
    
    # ç”¨æˆ·è¾“å…¥
    input_placeholder = "è¾“å…¥æ‚¨çš„é—®é¢˜..." + ("ï¼ˆè¿ç»­æ€è€ƒï¼‰" if st.session_state.continuous_mode else "")
    if prompt := st.chat_input(input_placeholder):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # å¤„ç†é—®é¢˜
        with st.chat_message("assistant"):
            try:
                if st.session_state.continuous_mode:
                    # è¿ç»­æ€è€ƒï¼šä½¿ç”¨ code_assistant_continous.py
                    if st.session_state.continuous_agent is None:
                        st.error("è¿ç»­æ€è€ƒæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ API å¯†é’¥é…ç½®")
                    else:
                        with st.spinner("æ­£åœ¨å¤„ç†ï¼ˆè¿ç»­æ€è€ƒï¼‰..."):
                            # ä½¿ç”¨å›ºå®šçš„ thread_id ä¿æŒå¯¹è¯è®°å¿†
                            config = {"configurable": {"thread_id": "streamlit_session"}}
                            full_response = st.session_state.continuous_agent.process_message(prompt, config)
                            
                            # æ˜¾ç¤ºå“åº”
                            st.markdown(full_response)
                            
                            # æ›´æ–°æ¶ˆæ¯å†å²
                            st.session_state.messages.append(AIMessage(content=full_response))
                else:
                    # æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨æµå¼å¤„ç†
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    # æµå¼è·å–å“åº”
                    for chunk in st.session_state.assistant.process_stream(
                        prompt,
                        st.session_state.messages[:-1]  # æ’é™¤åˆšæ·»åŠ çš„æ¶ˆæ¯
                    ):
                        # ç¡®ä¿ chunk æ˜¯å­—ç¬¦ä¸²ç±»å‹
                        if chunk:
                            if isinstance(chunk, str):
                                full_response += chunk
                                # å®æ—¶æ›´æ–°æ˜¾ç¤ºï¼ˆæ”¯æŒMarkdownï¼‰
                                response_placeholder.markdown(full_response + "â–Œ")
                            elif isinstance(chunk, dict):
                                # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–å†…å®¹
                                content = chunk.get("output", chunk.get("content", ""))
                                if content and isinstance(content, str):
                                    full_response += content
                                    response_placeholder.markdown(full_response + "â–Œ")
                            else:
                                # å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                                chunk_str = str(chunk)
                                full_response += chunk_str
                                response_placeholder.markdown(full_response + "â–Œ")
                    
                    # æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´å“åº”
                    response_placeholder.markdown(full_response)
                    
                    # æ›´æ–°æ¶ˆæ¯å†å²
                    st.session_state.messages.append(AIMessage(content=full_response))
                
            except Exception as e:
                st.error(f"å¤„ç†å‡ºé”™: {e}")
                import traceback
                st.code(traceback.format_exc())
    
    # ç®€æ´çš„è®¾ç½®åŒºåŸŸ - ä½¿ç”¨expanderè€Œä¸æ˜¯ä¾§è¾¹æ 
    with st.expander("âš™ï¸ è®¾ç½®", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            if st.button("æ¸…é™¤å¯¹è¯å†å²", type="secondary", use_container_width=True):
                st.session_state.messages = []
                st.rerun()
        with col2:
            if st.button("æ˜¾ç¤ºå¸®åŠ©", type="secondary", use_container_width=True):
                st.info("""
**åŠŸèƒ½è¯´æ˜ï¼š**
- **æ™®é€šå¯¹è¯**ï¼šç›´æ¥æé—®ï¼Œè·å¾—å›ç­”
- **ä»£ç ç”Ÿæˆ**ï¼šæè¿°éœ€æ±‚ï¼Œè‡ªåŠ¨ç”Ÿæˆä»£ç 
- **ä»£ç ä¼˜åŒ–**ï¼šæä¾›ä»£ç ï¼Œè‡ªåŠ¨ä¼˜åŒ–
- **ä»£ç å®¡æŸ¥**ï¼šæä¾›ä»£ç ï¼Œè·å¾—å®¡æŸ¥è¯„åˆ†å’Œå»ºè®®
                """)


if __name__ == "__main__":
    main()

